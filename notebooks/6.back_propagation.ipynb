{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZw9namamh3V"
   },
   "source": [
    "# **6. Mastering Backpropagation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LqdCQJhMmedx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtzMfOn-xp13"
   },
   "source": [
    "# **Let's prepare the dataset**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYZfs4uryhni"
   },
   "source": [
    "We use digits classification cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "I3-hZrNRzI1C"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RAD0EMKxo6U",
    "outputId": "dc19cc78-47fe-4203-922d-034c95936eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1797, 64)\n",
      "y shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "# Validate\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHCD938Uyl-q"
   },
   "source": [
    "Next, we split the data into train, valid, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "96_LF7BYyZlK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_Kw-TJjysXi",
    "outputId": "b42a6c6c-0b37-4dc9-d3da-7bbd89b597c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (1437, 64)\n",
      "y train shape: (1437,)\n",
      "X valid shape: (180, 64)\n",
      "y valid shape: (180,)\n",
      "X test shape : (180, 64)\n",
      "y test shape : (180,)\n"
     ]
    }
   ],
   "source": [
    "# Split train & (valid and test) --> 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    stratify=y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split valid & test --> 50:50\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    stratify=y_test,\n",
    "    test_size=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Validate\n",
    "print('X train shape:', X_train.shape)\n",
    "print('y train shape:', y_train.shape)\n",
    "print('X valid shape:', X_valid.shape)\n",
    "print('y valid shape:', y_valid.shape)\n",
    "print('X test shape :', X_test.shape)\n",
    "print('y test shape :', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qsG8zOK84Wh_"
   },
   "outputs": [],
   "source": [
    "# Convert to torch tensor\n",
    "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train)\n",
    "X_valid, y_valid = torch.tensor(X_valid, dtype=torch.float32), torch.tensor(y_valid)\n",
    "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hinxL0kb1OyP"
   },
   "source": [
    "# **Create a Comparison Function**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR8NRx58z18q"
   },
   "source": [
    "Next, we create a utility function to compare manual gradients to PyTorch gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "P1Fb0IfszwWh"
   },
   "outputs": [],
   "source": [
    "# This code is adapted from NN zero to hero, Andrej Karpathy\n",
    "def compare_grad(element, manual_grad, torch_node):\n",
    "    \"\"\"comparing manual gradients to PyTorch gradients\"\"\"\n",
    "    # Extract gradients\n",
    "    torch_grad = torch_node.grad\n",
    "\n",
    "    # Exact comparison\n",
    "    exact = torch.all(manual_grad == torch_grad).item()\n",
    "\n",
    "    # Approximate comparison\n",
    "    apprx = torch.allclose(manual_grad, torch_grad)\n",
    "\n",
    "    # Calculate maximum different between manual and torch gradients\n",
    "    max_diff = (\n",
    "        (manual_grad-torch_grad)    # calculate the difference\n",
    "        .abs()                      # then take the absolute value\n",
    "        .max()                      # and find the maximum value of it\n",
    "        .item()\n",
    "    )\n",
    "\n",
    "    # Print\n",
    "    print(f'{element:15s} | exact: {str(exact):5s} | approximate: {str(apprx):5s} | max diff.: {max_diff}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHPt29SN1Swx"
   },
   "source": [
    "# **Create the Neural Network using PyTorch**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvvGhw0z1aVd"
   },
   "source": [
    "- We create a neural network to classify the digits.\n",
    "- The architectures are\n",
    "  - Have 64 input dimensions\n",
    "  - Have 2 layers (1 hidden layer and 1 output layer)\n",
    "  - The output layer has 10 neurons (1 neuron for each digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mL_LHSCi1MTg"
   },
   "outputs": [],
   "source": [
    "# Defining the size\n",
    "n_in = 64\n",
    "n_hidden = 15\n",
    "n_out = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZwDeEMdM10oY",
    "outputId": "1e499416-bcfb-4c23-d037-b858edde574e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1165\n"
     ]
    }
   ],
   "source": [
    "# Create the Neural Network\n",
    "g = torch.Generator().manual_seed(42)\n",
    "\n",
    "# Layer 1 (The hidden layer)\n",
    "W1 = torch.randn((n_in, n_hidden),  generator=g) * (5/3) / (n_in**0.5)\n",
    "b1 = torch.randn(n_hidden,          generator=g) * 0.1\n",
    "\n",
    "# Layer 2 (The output layer)\n",
    "W2 = torch.randn((n_hidden, n_out), generator=g) * 0.1\n",
    "b2 = torch.randn(n_out,             generator=g) * 0.1\n",
    "\n",
    "# Batch normalization parameters\n",
    "bn_gain = torch.randn((1, n_hidden), generator=g) * 0.1 + 1.0\n",
    "bn_bias = torch.randn((1, n_hidden), generator=g) * 0.1\n",
    "\n",
    "# Get the parameters\n",
    "parameters = [W1, b1, W2, b2, bn_gain, bn_bias]\n",
    "print(sum(param.nelement() for param in parameters))\n",
    "\n",
    "# Activate the grad\n",
    "for param in parameters:\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMEqMt7Q2kUB"
   },
   "source": [
    "Next, we create a single forward pass that we want to calculate its gradients manually. Yeay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "shUqvUG02gx3",
    "outputId": "8f6d2348-85fe-4517-bd5c-c17b0cc6ab91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape: torch.Size([16, 64])\n",
      "y_batch shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# Create a batch learning\n",
    "batch_size = 16\n",
    "n = batch_size\n",
    "\n",
    "# Construct a minibatch\n",
    "mini_ix = torch.randint(0, X_train.shape[0], (batch_size,), generator=g)\n",
    "X_batch, y_batch = X_train[mini_ix], y_train[mini_ix]\n",
    "\n",
    "# Validate\n",
    "print('X_batch shape:', X_batch.shape)\n",
    "print('y_batch shape:', y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZQezbHC3DFL",
    "outputId": "953a6853-928c-4442-8f82-d25c46643171"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2752, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a forward pass\n",
    "\n",
    "# The hidden layer\n",
    "h_pre_bn = X_batch @ W1 + b1\n",
    "\n",
    "# Batch normalization layer\n",
    "bn_mean_i = (1./n) * h_pre_bn.sum(0, keepdim=True)\n",
    "bn_diff = h_pre_bn - bn_mean_i\n",
    "bn_diff2 = bn_diff**2\n",
    "bn_var = (1./(n-1)) * bn_diff2.sum(0, keepdim=True)\n",
    "bn_var_inv = (bn_var + 1e-5)**(-0.5)\n",
    "bn_raw = bn_diff * bn_var_inv\n",
    "h_pre_act = bn_gain * bn_raw + bn_bias\n",
    "\n",
    "# Non-linearity\n",
    "h = torch.tanh(h_pre_act)\n",
    "\n",
    "# The output layer\n",
    "logits = h @ W2 + b2\n",
    "\n",
    "# Calculate loss\n",
    "counts = logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1\n",
    "probs = counts * counts_sum_inv\n",
    "log_probs = probs.log()\n",
    "loss = -log_probs[range(n), y_batch].mean()\n",
    "\n",
    "# Do the backward pass with PyTorch\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "\n",
    "for p in [log_probs, probs, counts_sum_inv, counts_sum, counts,\n",
    "          logits, h, h_pre_act,\n",
    "          bn_raw, bn_var_inv, bn_var, bn_diff2, bn_diff, bn_mean_i,\n",
    "          h_pre_bn]:\n",
    "    p.retain_grad()\n",
    "\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjsBTQSlqe02"
   },
   "source": [
    "# **Task 1: Backprop the whole things manually**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPvFAK_Nqi1q"
   },
   "source": [
    "Similar to the pre-class video, perform backpropagation through the whole things manually and compare the gradients to the PyTorch gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zp0WMWM_qiab",
    "outputId": "e560b10b-457c-4656-d19a-faea20afa8f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
      "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
      "counts          | exact: True  | approximate: True  | max diff.: 0.0\n",
      "logits          | exact: True  | approximate: True  | max diff.: 0.0\n",
      "h               | exact: True  | approximate: True  | max diff.: 0.0\n",
      "W2              | exact: True  | approximate: True  | max diff.: 0.0\n",
      "b2              | exact: True  | approximate: True  | max diff.: 0.0\n",
      "h_pre_act       | exact: False | approximate: True  | max diff.: 9.313225746154785e-10\n",
      "bn_bias         | exact: False | approximate: True  | max diff.: 3.725290298461914e-09\n",
      "bn_gain         | exact: False | approximate: True  | max diff.: 1.862645149230957e-09\n",
      "bn_raw          | exact: False | approximate: True  | max diff.: 9.313225746154785e-10\n",
      "bn_var_inv      | exact: False | approximate: True  | max diff.: 1.4901161193847656e-08\n",
      "bn_var          | exact: False | approximate: True  | max diff.: 2.9103830456733704e-11\n",
      "bn_diff2        | exact: False | approximate: True  | max diff.: 1.8189894035458565e-12\n",
      "bn_diff         | exact: False | approximate: True  | max diff.: 2.3283064365386963e-10\n",
      "bn_mean_i       | exact: False | approximate: True  | max diff.: 9.313225746154785e-10\n",
      "h_pre_bn        | exact: False | approximate: True  | max diff.: 2.3283064365386963e-10\n",
      "W1              | exact: False | approximate: True  | max diff.: 1.6763806343078613e-08\n",
      "b1              | exact: False | approximate: True  | max diff.: 1.1932570487260818e-09\n"
     ]
    }
   ],
   "source": [
    "dlog_probs = torch.zeros_like(log_probs)\n",
    "dlog_probs[range(n), y_batch] = -1./n\n",
    "dprobs = (1./probs) * dlog_probs\n",
    "dcounts_sum_inv = (counts*dprobs).sum(1, keepdim=True)\n",
    "dcounts_sum = (-1) * (counts_sum**(-2)) * dcounts_sum_inv\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dlogits = counts * dcounts\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dh_pre_act = (1. - h**2) * dh\n",
    "dbn_bias = dh_pre_act.sum(0, keepdim=True)\n",
    "dbn_gain = (bn_raw * dh_pre_act).sum(0, keepdim=True)\n",
    "dbn_raw = bn_gain * dh_pre_act\n",
    "dbn_var_inv = (bn_diff*dbn_raw).sum(0, keepdim=True)\n",
    "dbn_var = (-0.5)*((bn_var + 1e-5)**(-1.5)) * dbn_var_inv\n",
    "dbn_diff2 = (1./(n-1)) * torch.ones_like(bn_diff2) * dbn_var\n",
    "dbn_diff = 2. * bn_diff * dbn_diff2\n",
    "dbn_diff += bn_var_inv * dbn_raw\n",
    "dbn_mean_i = -1. * dbn_diff.sum(0, keepdim=True)\n",
    "dh_pre_bn = dbn_diff.clone()\n",
    "dh_pre_bn += (1./n) * torch.ones_like(h_pre_bn) * dbn_mean_i\n",
    "dW1 = X_batch.T @ dh_pre_bn\n",
    "db1 = dh_pre_bn.sum(0)\n",
    "\n",
    "# Compare the gradients\n",
    "compare_grad('log_probs', dlog_probs, log_probs)\n",
    "compare_grad('probs', dprobs, probs)\n",
    "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
    "compare_grad('counts', dcounts, counts)\n",
    "compare_grad('logits', dlogits, logits)\n",
    "compare_grad('h', dh, h)\n",
    "compare_grad('W2', dW2, W2)\n",
    "compare_grad('b2', db2, b2)\n",
    "compare_grad('h_pre_act', dh_pre_act, h_pre_act)\n",
    "compare_grad('bn_bias', dbn_bias, bn_bias)\n",
    "compare_grad('bn_gain', dbn_gain, bn_gain)\n",
    "compare_grad('bn_raw', dbn_raw, bn_raw)\n",
    "compare_grad('bn_var_inv', dbn_var_inv, bn_var_inv)\n",
    "compare_grad('bn_var', dbn_var, bn_var)\n",
    "compare_grad('bn_diff2', dbn_diff2, bn_diff2)\n",
    "compare_grad('bn_diff', dbn_diff, bn_diff)\n",
    "compare_grad('bn_mean_i', dbn_mean_i, bn_mean_i)\n",
    "compare_grad('h_pre_bn', dh_pre_bn, h_pre_bn)\n",
    "compare_grad('W1', dW1, W1)\n",
    "compare_grad('b1', db1, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFyrf3hJGXh0"
   },
   "source": [
    "# **Task 2: Backprop the cross entropy loss**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRthUKa5GXh1"
   },
   "source": [
    "This is too long\n",
    "\n",
    "```python\n",
    "# Calculate loss\n",
    "counts = logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1\n",
    "probs = counts * counts_sum_inv\n",
    "log_probs = probs.log()\n",
    "loss = -log_probs[range(n), y_batch].mean()\n",
    "```\n",
    "\n",
    "We can simplify this as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLf5ib6yGT_I",
    "outputId": "c3a82756-7181-4643-ea77-5e06daba7fa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2752017974853516\n",
      "Difference to before: 2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "# Simplify\n",
    "loss_simple = F.cross_entropy(input=logits, target=y_batch)\n",
    "\n",
    "# Print\n",
    "print(loss_simple.item())\n",
    "print(f'Difference to before: {(loss_simple-loss).item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqLIlqr0HXmS"
   },
   "source": [
    "Then, find the gradients of loss w.r.t the logits manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C7NG8rGJHWFg",
    "outputId": "11f5a9e0-43eb-4b45-baf0-a17cb0397b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | max diff.: 7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# Softmax function\n",
    "dlogits_simple = F.softmax(logits, 1)\n",
    "dlogits_simple[range(n), y_batch] -= 1\n",
    "dlogits_simple /= n\n",
    "\n",
    "# Compare the gradients\n",
    "compare_grad('logits', dlogits_simple, logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYodVhswJxfK"
   },
   "source": [
    "# **Task 3: Train with manual backpropagation**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPVzug2GH-_F"
   },
   "source": [
    "First, reinitialize the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQrwuT_LIJYi",
    "outputId": "8c54c256-5f7f-40c4-8b48-9318b7256182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1165\n"
     ]
    }
   ],
   "source": [
    "# Create the Neural Network\n",
    "g = torch.Generator().manual_seed(42)\n",
    "\n",
    "# Layer 1 (The hidden layer)\n",
    "W1 = torch.randn((n_in, n_hidden),  generator=g) * (5/3) / (n_in**0.5)\n",
    "b1 = torch.randn(n_hidden,          generator=g) * 0.1\n",
    "\n",
    "# Layer 2 (The output layer)\n",
    "W2 = torch.randn((n_hidden, n_out), generator=g) * 0.1\n",
    "b2 = torch.randn(n_out,             generator=g) * 0.1\n",
    "\n",
    "# Batch normalization parameters\n",
    "bn_gain = torch.randn((1, n_hidden), generator=g) * 0.1 + 1.0\n",
    "bn_bias = torch.randn((1, n_hidden), generator=g) * 0.1\n",
    "\n",
    "# Get the parameters\n",
    "parameters = [W1, b1, W2, b2, bn_gain, bn_bias]\n",
    "print(sum(param.nelement() for param in parameters))\n",
    "\n",
    "# Activate the grad\n",
    "for param in parameters:\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2cqKERWILtC"
   },
   "source": [
    "Then let's train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fl3m3v3DILMq",
    "outputId": "9aaf7dd8-6f9b-4277-9564-acec6bf631b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0/  100000: 2.2752\n",
      "   10000/  100000: 0.0575\n",
      "   20000/  100000: 0.0262\n",
      "   30000/  100000: 0.0202\n",
      "   40000/  100000: 0.0043\n",
      "   50000/  100000: 0.0404\n",
      "   60000/  100000: 0.3940\n",
      "   70000/  100000: 0.0029\n",
      "   80000/  100000: 0.0019\n",
      "   90000/  100000: 0.0038\n"
     ]
    }
   ],
   "source": [
    "max_steps = 100_000\n",
    "batch_size = 16\n",
    "n = batch_size\n",
    "losses = []\n",
    "\n",
    "# We will calculate the grad manually\n",
    "with torch.no_grad():\n",
    "\n",
    "    # Start optimizing\n",
    "    for i in range(max_steps):\n",
    "        # Construct a minibatch\n",
    "        mini_ix = torch.randint(0, X_train.shape[0], (batch_size,), generator=g)\n",
    "        X_batch, y_batch = X_train[mini_ix], y_train[mini_ix]\n",
    "\n",
    "        # Perform the forward pass\n",
    "        h_pre_bn = X_batch @ W1 + b1\n",
    "        bn_mean_i = (1./n) * h_pre_bn.sum(0, keepdim=True)\n",
    "        bn_diff = h_pre_bn - bn_mean_i\n",
    "        bn_diff2 = bn_diff**2\n",
    "        bn_var = (1./(n-1)) * bn_diff2.sum(0, keepdim=True)\n",
    "        bn_var_inv = (bn_var + 1e-5)**(-0.5)\n",
    "        bn_raw = bn_diff * bn_var_inv\n",
    "        h_pre_act = bn_gain * bn_raw + bn_bias\n",
    "        h = torch.tanh(h_pre_act)\n",
    "        logits = h @ W2 + b2\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(input=logits, target=y_batch)\n",
    "\n",
    "        # Let's do the backward pass\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "\n",
    "        # Let's manually calculate the gradients\n",
    "        dlogits = F.softmax(logits, 1)\n",
    "        dlogits[range(n), y_batch] -= 1\n",
    "        dlogits /= n\n",
    "        dh = dlogits @ W2.T\n",
    "        dW2 = h.T @ dlogits\n",
    "        db2 = dlogits.sum(0)\n",
    "        dh_pre_act = (1. - h**2) * dh\n",
    "        dbn_bias = dh_pre_act.sum(0, keepdim=True)\n",
    "        dbn_gain = (bn_raw * dh_pre_act).sum(0, keepdim=True)\n",
    "        dbn_raw = bn_gain * dh_pre_act\n",
    "        dbn_var_inv = (bn_diff*dbn_raw).sum(0, keepdim=True)\n",
    "        dbn_var = (-0.5)*((bn_var + 1e-5)**(-1.5)) * dbn_var_inv\n",
    "        dbn_diff2 = (1./(n-1)) * torch.ones_like(bn_diff2) * dbn_var\n",
    "        dbn_diff = 2. * bn_diff * dbn_diff2\n",
    "        dbn_diff += bn_var_inv * dbn_raw\n",
    "        dbn_mean_i = -1. * dbn_diff.sum(0, keepdim=True)\n",
    "        dh_pre_bn = dbn_diff.clone()\n",
    "        dh_pre_bn += (1./n) * torch.ones_like(h_pre_bn) * dbn_mean_i\n",
    "        dW1 = X_batch.T @ dh_pre_bn\n",
    "        db1 = dh_pre_bn.sum(0)\n",
    "        grads = [dW1, db1, dW2, db2, dbn_gain, dbn_bias]  # store the grads of our model parameters\n",
    "\n",
    "        # Update the model parameters\n",
    "        lr = 0.1 if i < 50_000 else 0.01\n",
    "        for p, grad in zip(parameters, grads):\n",
    "            p.data += -lr * grad\n",
    "\n",
    "        # Track\n",
    "        if i%10000 == 0:\n",
    "            print(f'{i:8d}/{max_steps:8d}: {loss.item():.4f}')\n",
    "        losses.append(loss.log().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3of1KuWTNI9t"
   },
   "outputs": [],
   "source": [
    "# Calibrate the batch normalization layer\n",
    "with torch.no_grad():\n",
    "    # pass the training set through\n",
    "    h_pre_bn = X_train @ W1 + b1\n",
    "    bn_mean_i = (1./n) * h_pre_bn.sum(0, keepdim=True)\n",
    "    bn_diff = h_pre_bn - bn_mean_i\n",
    "    bn_diff2 = bn_diff**2\n",
    "    bn_var = (1./(n-1)) * bn_diff2.sum(0, keepdim=True)\n",
    "    bn_var_inv = (bn_var + 1e-5)**(-0.5)\n",
    "    bn_raw = bn_diff * bn_var_inv\n",
    "    h_pre_act = bn_gain * bn_raw + bn_bias\n",
    "\n",
    "    # measure the mean/std over the entire training set\n",
    "    bn_mean = h_pre_act.mean(0, keepdim=True)\n",
    "    bn_var = h_pre_act.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxSc2FegJ0Kb"
   },
   "source": [
    "Lets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTu3mdghJ3SP",
    "outputId": "cbac6d3c-d32e-4a76-fe61-bca5bd52cbf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.6982054710388184\n",
      "valid 0.9543957114219666\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def check_loss(split):\n",
    "    X, y = {\n",
    "    'train': (X_train, y_train),\n",
    "    'valid': (X_valid, y_valid),\n",
    "    'test': (X_test, y_test),\n",
    "    }[split]\n",
    "\n",
    "    # Perform a forward pass\n",
    "    h_pre_bn = X @ W1 + b1\n",
    "    bn_diff = h_pre_bn - bn_mean\n",
    "    bn_var_inv = (bn_var + 1e-5)**(-0.5)\n",
    "    bn_raw = bn_diff * bn_var_inv\n",
    "    h_pre_act = bn_gain * bn_raw + bn_bias\n",
    "    h = torch.tanh(h_pre_act)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "\n",
    "    print(split, loss.item())\n",
    "\n",
    "check_loss('train')\n",
    "check_loss('valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYlqpmIbKvS4"
   },
   "source": [
    "Let's predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YrYdHh48K5W4"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(split):\n",
    "    X, y = {\n",
    "    'train': (X_train, y_train),\n",
    "    'valid': (X_valid, y_valid),\n",
    "    'test': (X_test, y_test),\n",
    "    }[split]\n",
    "\n",
    "    # Perform a forward pass\n",
    "    h_pre_bn = X @ W1 + b1\n",
    "    bn_diff = h_pre_bn - bn_mean\n",
    "    bn_var_inv = (bn_var + 1e-5)**(-0.5)\n",
    "    bn_raw = bn_diff * bn_var_inv\n",
    "    h_pre_act = bn_gain * bn_raw + bn_bias\n",
    "    h = torch.tanh(h_pre_act)\n",
    "    logits = h @ W2 + b2\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    y_pred = probs.max(1).indices\n",
    "    y_pred_proba = probs.max(1).values\n",
    "\n",
    "    return y_pred, y_pred_proba\n",
    "\n",
    "y_test_pred, y_test_pred_proba = predict('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "FcQtZFrcJV9g",
    "outputId": "f46a90a5-78cf-442f-c522-ed2d0ca2b947"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x100 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "ix = torch.randint(0, X_test.shape[0], (5,))\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 1))\n",
    "for ax, img, act, pred, proba in zip(axes, X_test[ix], y_test[ix], y_test_pred[ix], y_test_pred_proba[ix]):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(img.reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title(f'Actual: {act}, Predicted: {pred}\\nProba: {proba:.4f}', fontsize=12)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "GtzMfOn-xp13",
    "hinxL0kb1OyP",
    "rHPt29SN1Swx",
    "vjsBTQSlqe02",
    "dFyrf3hJGXh0",
    "nYodVhswJxfK"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
