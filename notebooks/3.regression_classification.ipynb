{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ph7uNCKt2XSL"
   },
   "source": [
    "# **3. - A Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyyYWRoddhWd"
   },
   "source": [
    "# **3. Neural Network for Regression & Binary Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Vb0hUB2WcGl"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2xyABznyD5E"
   },
   "source": [
    "We're going to build a Neural Network Regression & Binary Classification using `PyTorch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32P_tHNDxF51"
   },
   "source": [
    "## **Task 1**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bxu1p5ASxKP7"
   },
   "source": [
    "- Create an array & matrix using `torch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZoPxoCe7xFV8",
    "outputId": "48e97cad-1231-4f8f-d5c1-2fcc4e41b261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "tensor([0., 0., 0.])\n",
      "\n",
      "data type:\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Create zeros vector\n",
    "bias = torch.zeros(3)\n",
    "\n",
    "print(\"data:\")\n",
    "print(bias)\n",
    "print(\"\")\n",
    "print(\"data type:\")\n",
    "print(type(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2SgOrUExjl2",
    "outputId": "b7e0fb60-271a-4c20-8464-6f4d817c0a4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "tensor([[7.7397e-01, 7.9601e-01, 8.6669e-01, 7.6944e-01],\n",
      "        [7.3907e-01, 1.0657e-04, 4.6490e-01, 8.4913e-01],\n",
      "        [9.1141e-01, 2.9187e-01, 5.1530e-01, 6.7008e-01]])\n",
      "\n",
      "data type:\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Create random matrix\n",
    "weight = torch.rand((3, 4))\n",
    "\n",
    "print(\"data:\")\n",
    "print(weight)\n",
    "print(\"\")\n",
    "print(\"data type:\")\n",
    "print(type(weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwzKepiNx1iH",
    "outputId": "66b5c688-4936-4bc8-e5b6-89d07c1ea0f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665],\n",
      "        [0.1366, 0.1025],\n",
      "        [0.1841, 0.7264]])\n",
      "\n",
      "data type:\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Create seed for random array/matrix in torch\n",
    "torch.manual_seed(123)\n",
    "\n",
    "weight = torch.rand((5, 2))\n",
    "\n",
    "print(\"data:\")\n",
    "print(weight)\n",
    "print(\"\")\n",
    "print(\"data type:\")\n",
    "print(type(weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNf-GyAlyQZ2"
   },
   "source": [
    "## **Task 2**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRh0cq7tyQZ4"
   },
   "source": [
    "- Create a class to represent a pre-activation function\n",
    "\n",
    "- Create some classes to represent activation function\n",
    "  - For regression: `Linear`\n",
    "  - For binary classification: `Sigmoid`\n",
    "  - For hidden layer: `ReLu` and `TanH`\n",
    "\n",
    "- Each classes has\n",
    "  - `__init__` method that return the input needed for initialization (for `Linear` only)\n",
    "  - `__call__` method that return the activation function\n",
    "  - `parameters` method that return the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OOiMrlKrxi9B"
   },
   "outputs": [],
   "source": [
    "# For pre-activation layer (including linear activation function)\n",
    "class Linear:\n",
    "    \"\"\"Layer of linear operation\"\"\"\n",
    "    def __init__(self, feature_in, feature_out, bias=True):\n",
    "        \"\"\"Generate model parameter in linear layer\"\"\"\n",
    "        # Generate random weight & biases\n",
    "        self.weight = torch.rand((feature_in, feature_out)).double()\n",
    "        if bias:\n",
    "            self.bias = torch.zeros(feature_out).double()\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"Return the weighted sum between model param & imputed value\"\"\"\n",
    "        weighted_sum = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out = weighted_sum + self.bias\n",
    "        else:\n",
    "            self.out = weighted_sum\n",
    "\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"Collect all parameters in a list\"\"\"\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "# For sigmoid layer\n",
    "class Sigmoid:\n",
    "    \"\"\"Sigmoid operation\"\"\"\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.sigmoid(x)\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        # no parameter included\n",
    "        return []\n",
    "\n",
    "# For ReLU layer\n",
    "class ReLU:\n",
    "    \"\"\"ReLU operation\"\"\"\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.relu(x)\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        # no parameter included\n",
    "        return []\n",
    "\n",
    "# For TanH layer\n",
    "class Tanh:\n",
    "    \"\"\"TanH operation\"\"\"\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        # no parameter included\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OV6BBCT31AGK"
   },
   "source": [
    "Let's validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjDw3hVy0_oO",
    "outputId": "5a51b8f8-307b-4cbb-bb1d-9c1b135db946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer object : <__main__.Linear object at 0x7c0abd0b2140>\n",
      "Layer param  :\n",
      " [tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665],\n",
      "        [0.1366, 0.1025],\n",
      "        [0.1841, 0.7264]], dtype=torch.float64), tensor([0., 0.], dtype=torch.float64)]\n",
      "Called param : tensor([2.4880, 8.5354], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Generate a linear layer of 5 input with 1 output & bias\n",
    "lyr = Linear(feature_in=5, feature_out=2, bias=True)\n",
    "\n",
    "# Pred\n",
    "xs = torch.tensor([1., 2., 3., 4., 5.]).double()\n",
    "ys = lyr(xs)\n",
    "\n",
    "print('Layer object :', lyr)\n",
    "print('Layer param  :\\n', lyr.parameters())\n",
    "print('Called param :', ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CXJGdsXv2CFI",
    "outputId": "83da2246-c2ad-4b08-fa6d-9ffa37bf596a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer object : <__main__.Tanh object at 0x7c0abd0b2920>\n",
      "Layer param  : []\n",
      "Called param : tensor([0.9863, 1.0000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Next, let's do the TanH function given the previous Linear layer\n",
    "next_lyr = Tanh()\n",
    "\n",
    "# Return the output\n",
    "ys_tanh = next_lyr(ys)\n",
    "\n",
    "print('Layer object :', next_lyr)\n",
    "print('Layer param  :', next_lyr.parameters())\n",
    "print('Called param :', ys_tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d-mcDDNqoCO"
   },
   "source": [
    "Nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03lc_jDzqmZu"
   },
   "source": [
    "## **Task 3**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Sv0QRgeqmZx"
   },
   "source": [
    "- From the previous tasks, we know that we can create a sequential operation to do a feed forward network.\n",
    "- Create a `Sequential` class to build a feed forward neural network where we can manually design the network architectures.\n",
    "- E.g.\n",
    "```python\n",
    "layers = [\n",
    "    Linear(3, 4), ReLU(),  # 1st layer, 3 inputs 4 neuron ReLU act. func.\n",
    "    Linear(4, 2), ReLU(),  # 2nd layer, 4 inputs 2 neurons ReLU\n",
    "    Linear(2, 1)           # Output layer, for Regression cases\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tp8DMcFQuVI9"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class Sequential:\n",
    "    \"\"\"Create a sequential procedures to build a neural network\"\"\"\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = copy.deepcopy(x)\n",
    "\n",
    "        # Iterate on given layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ic0X1hCbuzx0"
   },
   "source": [
    "Let's validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0aFuclAuzI2",
    "outputId": "8a80df22-5775-4942-9675-e2e0c591946c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Sequential object at 0x7c0abd0b1000>\n"
     ]
    }
   ],
   "source": [
    "# Say you want to create\n",
    "# A neural network with\n",
    "#  - 5 input\n",
    "#  - 3 hidden layer -> [4, 4, 3]\n",
    "#  - using TanH activation function in each layer\n",
    "#  - 1 output layer\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Create layer\n",
    "layers = [\n",
    "    Linear(feature_in=5, feature_out=4), Tanh(),\n",
    "    Linear(feature_in=4, feature_out=4), Tanh(),\n",
    "    Linear(feature_in=4, feature_out=3), Tanh(),\n",
    "    Linear(feature_in=3, feature_out=1)\n",
    "]\n",
    "\n",
    "# Create sequential model\n",
    "mdl = Sequential(layers = layers)\n",
    "\n",
    "print(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FVq6040SvXc3",
    "outputId": "7e27b0b0-d8e0-4305-8f81-53682537a865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer object : <__main__.Sequential object at 0x7c0abd0b1000>\n",
      "Layer param  :\n",
      " [tensor([[0.2961, 0.5166, 0.2517, 0.6886],\n",
      "        [0.0740, 0.8665, 0.1366, 0.1025],\n",
      "        [0.1841, 0.7264, 0.3153, 0.6871],\n",
      "        [0.0756, 0.1966, 0.3164, 0.4017],\n",
      "        [0.1186, 0.8274, 0.3821, 0.6605]], dtype=torch.float64), tensor([0., 0., 0., 0.], dtype=torch.float64), tensor([[0.8536, 0.5932, 0.6367, 0.9826],\n",
      "        [0.2745, 0.6584, 0.2775, 0.8573],\n",
      "        [0.8993, 0.0390, 0.9268, 0.7388],\n",
      "        [0.7179, 0.7058, 0.9156, 0.4340]], dtype=torch.float64), tensor([0., 0., 0., 0.], dtype=torch.float64), tensor([[0.0772, 0.3565, 0.1479],\n",
      "        [0.5331, 0.4066, 0.2318],\n",
      "        [0.4545, 0.9737, 0.4606],\n",
      "        [0.5159, 0.4220, 0.5786]], dtype=torch.float64), tensor([0., 0., 0.], dtype=torch.float64), tensor([[0.9455],\n",
      "        [0.8057],\n",
      "        [0.6775]], dtype=torch.float64), tensor([0.], dtype=torch.float64)]\n",
      "Called param : tensor([2.2478], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Pred\n",
    "xs = torch.tensor([1., 2., 3., 4., 5.]).double()\n",
    "ys = mdl(xs)\n",
    "\n",
    "print('Layer object :', mdl)\n",
    "print('Layer param  :\\n', mdl.parameters())\n",
    "print('Called param :', ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRGZci4MyDuD"
   },
   "source": [
    "## **Task 4**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeqyNud4yDuG"
   },
   "source": [
    "- Now, let's create a loss function.\n",
    "- In regression task, we define loss as a mean squared error\n",
    "\n",
    "$$\n",
    "MSE(\\mathbf{y}, \\hat{\\mathbf{y}})\n",
    "=\n",
    "\\cfrac{1}{N}\n",
    "\\sum_{i=1}^{N}\n",
    "(y_{i} - \\hat{y}_{i})^{2}\n",
    "$$\n",
    "\n",
    "- Named the function `mse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmmqj7M5yef0"
   },
   "outputs": [],
   "source": [
    "def mse_loss(target, input):\n",
    "    return torch.mean((target-input)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0XE3lxAzo8N"
   },
   "source": [
    "Let's check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WP3XI-W7zis7",
    "outputId": "eda6aa57-4f0f-42d2-f421-eca8464ed3ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The answer should be 1.\n",
    "mse_loss(target = torch.tensor([1., 1., 1., 1.]),\n",
    "         input = torch.tensor([0., 0., 0., 0.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDGfGucjz3rI"
   },
   "source": [
    "## **Task 5**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dw2wD3x0z3rL"
   },
   "source": [
    "- Let's perform a prediction with a Neuron\n",
    "- Optimize your model parameter using Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vsf0htin1MVW"
   },
   "source": [
    "*Load Library*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGDUYH_k0HuD"
   },
   "outputs": [],
   "source": [
    "# Load library\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gogjc741N74"
   },
   "source": [
    "*Prepare data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yH8EwfVN0m2t"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVtyZpAZ0p4O",
    "outputId": "a0248d55-09ee-4bfd-ab19-fb3d1b1fc9cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((353, 10), (44, 10), (45, 10))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test,\n",
    "                                                    test_size = 0.5,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "FZx47NMU04EC",
    "outputId": "35ba2c50-e97e-45c6-d624-522edee2cf1a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KSjbCSI1ATS"
   },
   "outputs": [],
   "source": [
    "# Transform data with scaler\n",
    "X_train_clean = scaler.transform(X_train)\n",
    "X_valid_clean = scaler.transform(X_valid)\n",
    "X_test_clean = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuP9SAvdKPuN"
   },
   "outputs": [],
   "source": [
    "# Transform data to torch.tensor format\n",
    "Xs_train = torch.tensor(X_train_clean)\n",
    "Xs_valid = torch.tensor(X_valid_clean)\n",
    "Xs_test = torch.tensor(X_test_clean)\n",
    "\n",
    "ys_train = torch.tensor(y_train).reshape(-1, 1)\n",
    "ys_valid = torch.tensor(y_valid).reshape(-1, 1)\n",
    "ys_test = torch.tensor(y_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Box57N5s1Q0W"
   },
   "source": [
    "*Create baseline model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggTw1AEE1SfB"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyRDr_V61ade",
    "outputId": "77ccd05e-68fe-4cff-9b27-7485ec3bae5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE score - Train : 6076.398012984615\n",
      "Baseline MSE score - Valid : 4977.640423791074\n"
     ]
    }
   ],
   "source": [
    "# Create object\n",
    "mdl_baseline = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Fit object\n",
    "mdl_baseline.fit(Xs_train, ys_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = mdl_baseline.predict(Xs_train)\n",
    "y_valid_pred = mdl_baseline.predict(Xs_valid)\n",
    "\n",
    "# Convert result to torch tensor\n",
    "ys_train_pred = torch.tensor(y_train_pred)\n",
    "ys_valid_pred = torch.tensor(y_valid_pred)\n",
    "\n",
    "# Show scores\n",
    "mse_train_baseline = mse_loss(ys_train_pred, ys_train)\n",
    "mse_valid_baseline = mse_loss(ys_valid_pred, ys_valid)\n",
    "\n",
    "print('Baseline MSE score - Train :', mse_train_baseline.item())\n",
    "print('Baseline MSE score - Valid :', mse_valid_baseline.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zoUDsR42iAM"
   },
   "source": [
    "*Great! Now let's create a Neuron model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPkAyMKm2mMO"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Neuron model\n",
    "layers = [\n",
    "    Linear(feature_in=10, feature_out=1, bias=True)\n",
    "]\n",
    "\n",
    "# Create the model\n",
    "mdl_neuron = Sequential(layers = layers)\n",
    "\n",
    "# Activate the computational graph gradient\n",
    "parameters = mdl_neuron.parameters()\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jeJ4xZ3A287t",
    "outputId": "59905a5e-a21c-41b8-b045-03e5a2c1848f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 | loss: 29553.3843\n",
      "iter: 101 | loss: 2889.9139\n",
      "iter: 201 | loss: 2883.3081\n",
      "iter: 301 | loss: 2878.7473\n",
      "iter: 401 | loss: 2875.5961\n",
      "iter: 501 | loss: 2873.4186\n",
      "iter: 601 | loss: 2871.9141\n",
      "iter: 701 | loss: 2870.8744\n",
      "iter: 801 | loss: 2870.1560\n",
      "iter: 901 | loss: 2869.6597\n",
      "iter: 1000 | loss: 2869.3195\n",
      "Neuron MSE score - Train : 2869.316661272341\n",
      "Neuron MSE score - Valid : 2755.875224468187\n"
     ]
    }
   ],
   "source": [
    "# Now, let's perform the Gradient Descent\n",
    "for k in range(1000):\n",
    "    # Do the forward pass to get prediction & loss\n",
    "    y_pred = mdl_neuron(Xs_train)\n",
    "    loss = mse_loss(y_pred, ys_train)\n",
    "\n",
    "    # Do the backpropagation\n",
    "    # Always reset the parameter gradient every iterations\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    # Then, do the backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Now, let's update the model\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad\n",
    "\n",
    "    # Print\n",
    "    if k==0 or k==999 or k%100==0:\n",
    "        print(f'iter: {k+1} | loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Show final scores\n",
    "ys_train_pred = mdl_neuron(Xs_train)\n",
    "ys_valid_pred = mdl_neuron(Xs_valid)\n",
    "\n",
    "print('Neuron MSE score - Train :', mse_loss(ys_train_pred, ys_train).item())\n",
    "print('Neuron MSE score - Valid :', mse_loss(ys_valid_pred, ys_valid).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIZBDLzGK82e"
   },
   "source": [
    "*Nice! There is a huge improvement in train & valid dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FULapIIxG5XQ",
    "outputId": "feeef39b-60f9-4010-9879-775487f50c29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.7891],\n",
      "        [-11.4982],\n",
      "        [ 25.7320],\n",
      "        [ 16.7887],\n",
      "        [-37.9602],\n",
      "        [ 19.5654],\n",
      "        [  4.8145],\n",
      "        [ 12.2476],\n",
      "        [ 32.6712],\n",
      "        [  2.3983]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([153.7365], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "for p in parameters:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hx1vT9LzLncO"
   },
   "source": [
    "*Remember, 1 neuron = a linear regression model. Let's prove this*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXsNyqtRLmD1",
    "outputId": "ce08fa44-97ae-48cf-c2ea-76320420c337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR MSE score - Train : 2868.549702835577\n",
      "LR MSE score - Valid : 2765.853591002306\n",
      "Model parameters:\n",
      "[[  1.75375799 -11.51180908  25.60712144  16.82887167 -44.44885564\n",
      "   24.64095356   7.67697768  13.1387839   35.16119521   2.35136365]] [153.73654391]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mdl_lr = LinearRegression()\n",
    "mdl_lr.fit(Xs_train, ys_train)\n",
    "\n",
    "lr_train_score = mean_squared_error(mdl_lr.predict(Xs_train), ys_train)\n",
    "lr_valid_score = mean_squared_error(mdl_lr.predict(Xs_valid), ys_valid)\n",
    "\n",
    "print('LR MSE score - Train :', lr_train_score)\n",
    "print('LR MSE score - Valid :', lr_valid_score)\n",
    "print('Model parameters:')\n",
    "print(mdl_lr.coef_, mdl_lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoGp2mQj8fMt"
   },
   "source": [
    "## **Task 6**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLYh5txL8fNz"
   },
   "source": [
    "- Let's perform a prediction with a Neural Network\n",
    "- Optimize your model parameter using Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbBfOj707Pga"
   },
   "source": [
    "*Now, let's create a Neural Network*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FIrmNWXH7U2P"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Neural Network model\n",
    "# 1 hidden layer, 6 neuron, TanH activation function\n",
    "layers = [\n",
    "    Linear(feature_in=10, feature_out=6, bias=True), Tanh(),\n",
    "    Linear(feature_in=6, feature_out=1, bias=True)\n",
    "]\n",
    "\n",
    "# Create the model\n",
    "mdl_nn = Sequential(layers = layers)\n",
    "\n",
    "# Activate the computational graph gradient\n",
    "parameters = mdl_nn.parameters()\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IfUuBYvC7U2y",
    "outputId": "badd27ef-5937-4775-b108-053a08f7a21b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 | loss: 29539.4910\n",
      "iter: 101 | loss: 2779.2292\n",
      "iter: 201 | loss: 2547.1046\n",
      "iter: 301 | loss: 2464.0943\n",
      "iter: 401 | loss: 2473.8480\n",
      "iter: 501 | loss: 2491.3797\n",
      "iter: 601 | loss: 2446.9829\n",
      "iter: 701 | loss: 2447.0473\n",
      "iter: 801 | loss: 2447.2638\n",
      "iter: 901 | loss: 2447.3159\n",
      "iter: 1000 | loss: 2446.7670\n",
      "Neuron MSE score - Train : 2445.987691411018\n",
      "Neuron MSE score - Valid : 2822.952408174069\n"
     ]
    }
   ],
   "source": [
    "# Now, let's perform the Gradient Descent\n",
    "for k in range(1000):\n",
    "    # Do the forward pass to get prediction & loss\n",
    "    y_pred = mdl_nn(Xs_train)\n",
    "    loss = mse_loss(y_pred, ys_train)\n",
    "\n",
    "    # Do the backpropagation\n",
    "    # Always reset the parameter gradient every iterations\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    # Then, do the backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Now, let's update the model\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad\n",
    "\n",
    "    # Print\n",
    "    if k==0 or k==999 or k%100==0:\n",
    "        print(f'iter: {k+1} | loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Show final scores\n",
    "ys_train_pred = mdl_nn(Xs_train)\n",
    "ys_valid_pred = mdl_nn(Xs_valid)\n",
    "\n",
    "print('Neuron MSE score - Train :', mse_loss(ys_train_pred, ys_train).item())\n",
    "print('Neuron MSE score - Valid :', mse_loss(ys_valid_pred, ys_valid).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNQMlxS_8TYT"
   },
   "source": [
    "*Nice!, we have better train score, but beware of the model <u>overfit</u>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOfwk0rP6706"
   },
   "source": [
    "## **Exercise**\n",
    "---\n",
    "\n",
    "- Build your own Neural Network Model\n",
    "- You can design your own architecture\n",
    "- Compare the results with your initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ky1fF4wM7Eqa"
   },
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63iiJrtk8xrZ"
   },
   "source": [
    "## **Task 7**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnzvMMu48xr-"
   },
   "source": [
    "- For the binary classification network, we need to build the loss function.\n",
    "- Remember, we can use the *binary crossentropy loss* or *negative log-likelihood*\n",
    "\n",
    "$$\n",
    "NLL = \\cfrac{1}{N}\n",
    "\\sum_{i=1}^{N}\n",
    "\\left[\n",
    "\\sum_{j=1}^{C}\n",
    "\\mathbf{1}_{y^{(i)}=c} \\cdot \\log (P(y^{(i)}=c|x^{(i)}))\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djAFjRjm9qaq"
   },
   "source": [
    "- Named the function as `bce_loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gXFZapC8xsA"
   },
   "outputs": [],
   "source": [
    "def bce_loss(target, input):\n",
    "    return -torch.mean(input*torch.log(target+1e-16) + (1-input)*torch.log(1-(target+1e-16)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYyOsL2A8xsC"
   },
   "source": [
    "Let's check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bAb4IOvR8xsD",
    "outputId": "a4dbcfae-bb0b-4df5-dac5-a8aad9ff7be8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2523)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The answer should be 0.2523\n",
    "bce_loss(target = torch.tensor([0.9, 0.5, 0.1, 0.1]),\n",
    "         input = torch.tensor([1, 1, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELHAM8hD-kDD"
   },
   "source": [
    "## **Task 8**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIivzKQp-kD-"
   },
   "source": [
    "- Let's perform a binary classification prediction with a Neuron\n",
    "- Optimize your model parameter using Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vuv5jBL-kEA"
   },
   "source": [
    "*Load Library*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMPrY3o0-kEC"
   },
   "outputs": [],
   "source": [
    "# Load library\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFZt5MJ7-kEE"
   },
   "source": [
    "*Prepare data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9TxmNn7-kEF"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, y = load_iris(return_X_y=True)\n",
    "y = np.where(y==2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sb69AYP0-kEG",
    "outputId": "180de650-7802-4e7b-ae77-9aa65ffed185"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (15, 4), (15, 4))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test,\n",
    "                                                    test_size = 0.5,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "r3FY_aZh-kEN",
    "outputId": "30b00391-f5c0-48cf-aea9-a81bc03025d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLz6USvh-kEV"
   },
   "outputs": [],
   "source": [
    "# Transform data with scaler\n",
    "X_train_clean = scaler.transform(X_train)\n",
    "X_valid_clean = scaler.transform(X_valid)\n",
    "X_test_clean = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08bYVhjp-kEX"
   },
   "outputs": [],
   "source": [
    "# Transform data to torch.tensor format\n",
    "Xs_train = torch.tensor(X_train_clean)\n",
    "Xs_valid = torch.tensor(X_valid_clean)\n",
    "Xs_test = torch.tensor(X_test_clean)\n",
    "\n",
    "ys_train = torch.tensor(y_train).reshape(-1, 1)\n",
    "ys_valid = torch.tensor(y_valid).reshape(-1, 1)\n",
    "ys_test = torch.tensor(y_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37POObIf-kEY"
   },
   "source": [
    "*Create baseline model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GRmkMP0-kEd"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WsGif53H-kEf",
    "outputId": "b2ffa5e0-0be7-4004-f6ef-64a67715a864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline BCE score - Train : 11.973442483569041\n",
      "Baseline BCE score - Valid : 17.192635361022212\n"
     ]
    }
   ],
   "source": [
    "# Create object\n",
    "mdl_baseline = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Fit object\n",
    "mdl_baseline.fit(Xs_train, ys_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = mdl_baseline.predict_proba(Xs_train)[:, 1]\n",
    "y_valid_pred = mdl_baseline.predict_proba(Xs_valid)[:, 1]\n",
    "\n",
    "# Convert result to torch tensor\n",
    "ys_train_pred = torch.tensor(y_train_pred)\n",
    "ys_valid_pred = torch.tensor(y_valid_pred)\n",
    "\n",
    "# Show scores\n",
    "bce_train_baseline = bce_loss(ys_train_pred, ys_train)\n",
    "bce_valid_baseline = bce_loss(ys_valid_pred, ys_valid)\n",
    "\n",
    "print('Baseline BCE score - Train :', bce_train_baseline.item())\n",
    "print('Baseline BCE score - Valid :', bce_valid_baseline.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mq8-6ACZ-kEh"
   },
   "source": [
    "*Great! Now let's create a Neuron model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIqxlQ11-kEi"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Neuron model\n",
    "layers = [\n",
    "    Linear(feature_in=4, feature_out=1, bias=True), Sigmoid()\n",
    "]\n",
    "\n",
    "# Create the model\n",
    "mdl_neuron = Sequential(layers = layers)\n",
    "\n",
    "# Activate the computational graph gradient\n",
    "parameters = mdl_neuron.parameters()\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KfoXcRXs-kEj",
    "outputId": "e10aaf78-48ad-4af4-90cc-368c309522f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 | loss: 0.0678\n",
      "iter: 101 | loss: 0.0675\n",
      "iter: 201 | loss: 0.0673\n",
      "iter: 301 | loss: 0.0671\n",
      "iter: 401 | loss: 0.0668\n",
      "iter: 501 | loss: 0.0666\n",
      "iter: 601 | loss: 0.0664\n",
      "iter: 701 | loss: 0.0662\n",
      "iter: 801 | loss: 0.0660\n",
      "iter: 901 | loss: 0.0657\n",
      "iter: 1000 | loss: 0.0655\n",
      "Neuron BCE score - Train : 0.06553821298705326\n",
      "Neuron BCE score - Valid : 0.040261311328580913\n"
     ]
    }
   ],
   "source": [
    "# Now, let's perform the Gradient Descent\n",
    "for k in range(1000):\n",
    "    # Do the forward pass to get prediction & loss\n",
    "    y_pred = mdl_neuron(Xs_train)\n",
    "    loss = bce_loss(y_pred, ys_train)\n",
    "\n",
    "    # Do the backpropagation\n",
    "    # Always reset the parameter gradient every iterations\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    # Then, do the backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Now, let's update the model\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad\n",
    "\n",
    "    # Print\n",
    "    if k==0 or k==999 or k%100==0:\n",
    "        print(f'iter: {k+1} | loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Show final scores\n",
    "ys_train_pred = mdl_neuron(Xs_train)\n",
    "ys_valid_pred = mdl_neuron(Xs_valid)\n",
    "\n",
    "print('Neuron BCE score - Train :', bce_loss(ys_train_pred, ys_train).item())\n",
    "print('Neuron BCE score - Valid :', bce_loss(ys_valid_pred, ys_valid).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGvIiUKb-kEm"
   },
   "source": [
    "*Nice! There is a huge improvement in train & valid dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2lfMiGe-kEn",
    "outputId": "be64cd76-8e89-4263-c7ef-85323effff6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5392],\n",
      "        [-1.5131],\n",
      "        [ 5.2418],\n",
      "        [ 6.0195]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([-7.6034], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "for p in parameters:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OdDszdd-kEr"
   },
   "source": [
    "*Remember, 1 neuron = a linear regression model. Let's prove this*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xSO2v0Ic-kEv",
    "outputId": "0d123bcb-4369-45ad-e501-05ccaab49039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR BCE score - Train : 0.04657793270205176\n",
      "LR BCE score - Valid : 0.02114910543256611\n",
      "Model parameters:\n",
      "[[-1.75013656 -3.06911108 14.50150061 12.33229584]] [-18.62682849]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "mdl_lr = LogisticRegression(penalty=\"none\")\n",
    "mdl_lr.fit(Xs_train, ys_train.flatten())\n",
    "\n",
    "lr_train_score = log_loss(ys_train.flatten(), mdl_lr.predict_proba(Xs_train))\n",
    "lr_valid_score = log_loss(ys_valid.flatten(), mdl_lr.predict_proba(Xs_valid))\n",
    "\n",
    "print('LR BCE score - Train :', lr_train_score)\n",
    "print('LR BCE score - Valid :', lr_valid_score)\n",
    "print('Model parameters:')\n",
    "print(mdl_lr.coef_, mdl_lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asbSHvK-Jn7d"
   },
   "source": [
    "## **Task 9**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgTkTK2pJn7e"
   },
   "source": [
    "- Let's perform a prediction with a Neural Network\n",
    "- Optimize your model parameter using Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYySgty5Jn7e"
   },
   "source": [
    "*Now, let's create a Neural Network*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BvX08zoJn7f"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Neural Network model\n",
    "# 1 hidden layer, 6 neuron, TanH activation function\n",
    "layers = [\n",
    "    Linear(feature_in=4, feature_out=3, bias=True), Tanh(),\n",
    "    Linear(feature_in=3, feature_out=2, bias=True), Tanh(),\n",
    "    Linear(feature_in=2, feature_out=1, bias=True), Sigmoid()\n",
    "]\n",
    "\n",
    "# Create the model\n",
    "mdl_nn = Sequential(layers = layers)\n",
    "\n",
    "# Activate the computational graph gradient\n",
    "parameters = mdl_nn.parameters()\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qu9BouS-Jn7f",
    "outputId": "dde65d2f-19fb-4f5b-dec7-16b1e78774a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 | loss: 0.0262\n",
      "iter: 101 | loss: 0.0245\n",
      "iter: 201 | loss: 0.0228\n",
      "iter: 301 | loss: 0.0212\n",
      "iter: 401 | loss: 0.0196\n",
      "iter: 501 | loss: 0.0181\n",
      "iter: 601 | loss: 0.0167\n",
      "iter: 701 | loss: 0.0154\n",
      "iter: 801 | loss: 0.0143\n",
      "iter: 901 | loss: 0.0132\n",
      "iter: 1000 | loss: 0.0122\n",
      "Neuron BCE score - Train : 0.012227674938569438\n",
      "Neuron BCE score - Valid : 0.016059593978176502\n"
     ]
    }
   ],
   "source": [
    "# Now, let's perform the Gradient Descent\n",
    "for k in range(1000):\n",
    "    # Do the forward pass to get prediction & loss\n",
    "    y_pred = mdl_nn(Xs_train)\n",
    "    loss = bce_loss(y_pred, ys_train)\n",
    "\n",
    "    # Do the backpropagation\n",
    "    # Always reset the parameter gradient every iterations\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    # Then, do the backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Now, let's update the model\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad\n",
    "\n",
    "    # Print\n",
    "    if k==0 or k==999 or k%100==0:\n",
    "        print(f'iter: {k+1} | loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Show final scores\n",
    "ys_train_pred = mdl_nn(Xs_train)\n",
    "ys_valid_pred = mdl_nn(Xs_valid)\n",
    "\n",
    "print('Neuron BCE score - Train :', bce_loss(ys_train_pred, ys_train).item())\n",
    "print('Neuron BCE score - Valid :', bce_loss(ys_valid_pred, ys_valid).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nC0S3kXJn7g"
   },
   "source": [
    "*Nice!, we have better train score, but beware of the model <u>overfit</u>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qRhX4jMAKYO9",
    "outputId": "4003c29d-40b8-43d6-8b98-c64dc1f3db56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9349, -0.3910, -0.3746],\n",
      "        [ 2.3500, -0.7671, -0.5239],\n",
      "        [ 0.4740,  1.7023,  1.2191],\n",
      "        [ 0.8445,  0.4981,  0.7815]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([-0.0442, -1.1513, -1.6828], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[1.1042, 1.3135],\n",
      "        [1.5660, 1.6125],\n",
      "        [1.6127, 2.0754]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([-0.6029, -0.6148], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[3.6079],\n",
      "        [4.4077]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([-0.3816], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "for p in parameters:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mW2n9YHEJn7g"
   },
   "source": [
    "## **Exercise**\n",
    "---\n",
    "\n",
    "- Build your own Neural Network Model\n",
    "- You can design your own architecture\n",
    "- Compare the results with your initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TS81BGY2Jn7h"
   },
   "outputs": [],
   "source": [
    "# Code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "32P_tHNDxF51",
    "RNf-GyAlyQZ2",
    "03lc_jDzqmZu",
    "yRGZci4MyDuD",
    "cDGfGucjz3rI",
    "uoGp2mQj8fMt",
    "vOfwk0rP6706",
    "63iiJrtk8xrZ",
    "asbSHvK-Jn7d",
    "mW2n9YHEJn7g"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
